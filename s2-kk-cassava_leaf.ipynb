{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_header(data : pd.DataFrame, feature_name: str):\n",
    "    columns_name = [f'{feature_name}_{i}' for i in range(1, len(data.columns))]\n",
    "    data.columns = columns_name + ['label']\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Load LBP feature dataset\n",
    "lbp_data = pd.read_csv(f'./datasets/Fitur_LBPuniform_Cassava Leaf.csv')\n",
    "lbp_data = format_data_header(lbp_data, 'lbp')\n",
    "\n",
    "# Load wavelet feature dataset\n",
    "wavelet_data = pd.read_csv(f'./datasets/Fitur_Wavelet_1234_Cassava Leaf.csv')\n",
    "wavelet_data = format_data_header(wavelet_data, 'wavelet')\n",
    "\n",
    "# Round label value\n",
    "lbp_data['label'] = lbp_data['label'].apply(lambda x: round(x, 0))\n",
    "wavelet_data['label'] = lbp_data['label'].apply(lambda x: round(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion the feature\n",
    "merged_data = pd.concat([lbp_data.drop('label', axis=1), wavelet_data], axis=1)\n",
    "merged_data.columns\n",
    "\n",
    "# Check data imbalance\n",
    "# Count the number of samples in each class\n",
    "counts = merged_data['label'].value_counts()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = merged_data.drop('label', axis=1)\n",
    "y = merged_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of principal components to keep\n",
    "n_components = 20\n",
    "\n",
    "# Fit the PCA model to the training data\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the trained PCA model\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "3: 13158\n",
      "4: 2577\n",
      "2: 2386\n",
      "1: 2189\n",
      "0: 1086\n",
      "Accuracy: 0.46869158878504674\n"
     ]
    }
   ],
   "source": [
    "# Using RandomOverSampler for handling imbalance\n",
    "\n",
    "# Print the class distribution\n",
    "print('Class distribution:')\n",
    "for label, count in counts.items():\n",
    "    print(f'{label}: {count}')\n",
    "\n",
    "# Create a SMOTE oversampler\n",
    "over = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit the oversampler on the training data and oversample the minority classes\n",
    "X_train_resampled, y_train_resampled = over.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train an SVM classifier on the fused feature vector\n",
    "clf = SVC()\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "3: 13158\n",
      "4: 2577\n",
      "2: 2386\n",
      "1: 2189\n",
      "0: 1086\n",
      "Accuracy: 0.49929906542056074\n"
     ]
    }
   ],
   "source": [
    "# Using ADASYN for handling imbalance\n",
    "\n",
    "# Print the class distribution\n",
    "print('Class distribution:')\n",
    "for label, count in counts.items():\n",
    "    print(f'{label}: {count}')\n",
    "\n",
    "# Create a SMOTE oversampler\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "# Fit the oversampler on the training data and oversample the minority classes\n",
    "X_train_resampled, y_train_resampled = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train an SVM classifier on the fused feature vector\n",
    "clf = SVC()\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "3: 13158\n",
      "4: 2577\n",
      "2: 2386\n",
      "1: 2189\n",
      "0: 1086\n",
      "Accuracy: 0.4133177570093458\n"
     ]
    }
   ],
   "source": [
    "# Using SMOTE for handling imbalance\n",
    "\n",
    "# Print the class distribution\n",
    "print('Class distribution:')\n",
    "for label, count in counts.items():\n",
    "    print(f'{label}: {count}')\n",
    "\n",
    "# Create a SMOTE oversampler\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Fit the oversampler on the training data and oversample the minority classes\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train an SVM classifier on the fused feature vector\n",
    "clf = SVC()\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6439252336448598\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBoost model with desired hyperparameters\n",
    "model = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 20:50:25.760424: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535/535 [==============================] - 7s 13ms/step - loss: 1.1721 - accuracy: 0.6046\n",
      "Epoch 2/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 1.0480 - accuracy: 0.6314\n",
      "Epoch 3/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 1.0299 - accuracy: 0.6349\n",
      "Epoch 4/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 1.0188 - accuracy: 0.6360\n",
      "Epoch 5/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 1.0094 - accuracy: 0.6393\n",
      "Epoch 6/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 0.9996 - accuracy: 0.6420\n",
      "Epoch 7/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 0.9912 - accuracy: 0.6427\n",
      "Epoch 8/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 0.9837 - accuracy: 0.6455\n",
      "Epoch 9/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 0.9783 - accuracy: 0.6489\n",
      "Epoch 10/10\n",
      "535/535 [==============================] - 7s 13ms/step - loss: 0.9718 - accuracy: 0.6503\n",
      "134/134 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.6474299065420561\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape of the model\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Define the DNN model with desired architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with the desired loss function, optimizer, and evaluation metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Convert the labels to one-hot encoded format\n",
    "y_train_encoded = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_encoded = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train_encoded, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_encoded = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities back to class labels\n",
    "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
    "\n",
    "# Evaluate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the base classifiers to be used in the ensemble\n",
    "classifiers = [\n",
    "    # ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "    # ('et', ExtraTreesClassifier(n_estimators=100, random_state=42)),\n",
    "    # ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    # ('mlp', MLPClassifier(hidden_layer_sizes=(64,), activation='relu', solver='adam', random_state=42)),\n",
    "    # ('svm', make_pipeline(StandardScaler(), SVC(kernel='rbf', C=10, gamma=0.1)))\n",
    "]\n",
    "\n",
    "# Create the ensemble model using a VotingClassifier with 'hard' voting\n",
    "model = VotingClassifier(classifiers, voting='hard')\n",
    "\n",
    "# Train the ensemble model on the training data using cross-validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))\n",
    "\n",
    "# Fit the ensemble model to the full training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
